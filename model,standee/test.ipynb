{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install nlpaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import nlpaug.augmenter.word as naw\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('emotions_data_expanded.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Question No</th>\n",
       "      <th>Emotion1</th>\n",
       "      <th>Emotion2</th>\n",
       "      <th>Emotion3</th>\n",
       "      <th>Emotion4</th>\n",
       "      <th>Emotion5</th>\n",
       "      <th>Emotion6</th>\n",
       "      <th>Emotion7</th>\n",
       "      <th>Emotion8</th>\n",
       "      <th>Emotion9</th>\n",
       "      <th>Emotion10</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>GADscore</th>\n",
       "      <th>HeartRate</th>\n",
       "      <th>OxygenLevel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65d73565463b536e04d9a325</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>sad</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>7</td>\n",
       "      <td>90</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65d73565463b536e04d9a325</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>fear</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>sad</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>sad</td>\n",
       "      <td>neutral</td>\n",
       "      <td>7</td>\n",
       "      <td>97</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65d73565463b536e04d9a325</td>\n",
       "      <td>3</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "      <td>neutral</td>\n",
       "      <td>7</td>\n",
       "      <td>111</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65d73565463b536e04d9a325</td>\n",
       "      <td>4</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>fear</td>\n",
       "      <td>angry</td>\n",
       "      <td>fear</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>7</td>\n",
       "      <td>89</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65d73565463b536e04d9a325</td>\n",
       "      <td>5</td>\n",
       "      <td>happy</td>\n",
       "      <td>neutral</td>\n",
       "      <td>angry</td>\n",
       "      <td>angry</td>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "      <td>angry</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>7</td>\n",
       "      <td>105</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  PatientID  Question No Emotion1 Emotion2 Emotion3 Emotion4  \\\n",
       "0  65d73565463b536e04d9a325            1  neutral  neutral  neutral      sad   \n",
       "1  65d73565463b536e04d9a325            2  neutral     fear  neutral  neutral   \n",
       "2  65d73565463b536e04d9a325            3  neutral  neutral  neutral  neutral   \n",
       "3  65d73565463b536e04d9a325            4  neutral  neutral  neutral  neutral   \n",
       "4  65d73565463b536e04d9a325            5    happy  neutral    angry    angry   \n",
       "\n",
       "  Emotion5 Emotion6 Emotion7 Emotion8 Emotion9 Emotion10 Sentiment  GADscore  \\\n",
       "0  neutral  neutral  neutral  neutral  neutral   neutral   neutral         7   \n",
       "1  neutral  neutral      sad  neutral  neutral       sad   neutral         7   \n",
       "2  neutral  neutral  neutral  neutral    happy     happy   neutral         7   \n",
       "3     fear    angry     fear  neutral  neutral   neutral   neutral         7   \n",
       "4    happy    happy    angry  neutral  neutral   neutral   neutral         7   \n",
       "\n",
       "   HeartRate  OxygenLevel  \n",
       "0         90          119  \n",
       "1         97           81  \n",
       "2        111           83  \n",
       "3         89           92  \n",
       "4        105           94  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "emotions = ['Emotion1', 'Emotion2', 'Emotion3', 'Emotion4', 'Emotion5', \n",
    "            'Emotion6', 'Emotion7', 'Emotion8', 'Emotion9', 'Emotion10']\n",
    "\n",
    "gad_min, gad_max = 70, 130  \n",
    "heart_rate_min, heart_rate_max = 70, 120  \n",
    "oxygen_level_min, oxygen_level_max = 80, 100 \n",
    "\n",
    "augmented_datasets = []\n",
    "\n",
    "for _ in range(25):\n",
    "    augmented_rows = []\n",
    "    for _, row in df.iterrows():\n",
    "        # Shuffle emotions\n",
    "        shuffled_emotions = row[emotions].tolist()\n",
    "        random.shuffle(shuffled_emotions)\n",
    "        \n",
    "        gad_score = random.randint(gad_min, gad_max)\n",
    "        heart_rate = random.randint(heart_rate_min, heart_rate_max)\n",
    "        oxygen_level = random.randint(oxygen_level_min, oxygen_level_max)\n",
    "        \n",
    "        # Update row with augmented emotions and numerical features\n",
    "        row.update(pd.Series(shuffled_emotions, index=emotions))\n",
    "        row['GADscore'] = gad_score\n",
    "        row['HeartRate'] = heart_rate\n",
    "        row['OxygenLevel'] = oxygen_level\n",
    "        \n",
    "        augmented_rows.append(row)\n",
    "    \n",
    "    # Create a new DataFrame with augmented emotions and numerical features\n",
    "    augmented_df = pd.DataFrame(augmented_rows)\n",
    "    \n",
    "    # Append the augmented dataset to the list\n",
    "    augmented_datasets.append(augmented_df)\n",
    "\n",
    "# Concatenate all augmented datasets\n",
    "final_dataset = pd.concat(augmented_datasets, ignore_index=True)\n",
    "\n",
    "# Save the final dataset to a new CSV file\n",
    "final_dataset.to_csv('augmented_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question No</th>\n",
       "      <th>GADscore</th>\n",
       "      <th>HeartRate</th>\n",
       "      <th>OxygenLevel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.500000</td>\n",
       "      <td>100.007500</td>\n",
       "      <td>95.043167</td>\n",
       "      <td>89.949000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.872521</td>\n",
       "      <td>17.696515</td>\n",
       "      <td>14.677586</td>\n",
       "      <td>6.014241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>82.750000</td>\n",
       "      <td>85.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.500000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Question No     GADscore    HeartRate  OxygenLevel\n",
       "count  6000.000000  6000.000000  6000.000000  6000.000000\n",
       "mean      5.500000   100.007500    95.043167    89.949000\n",
       "std       2.872521    17.696515    14.677586     6.014241\n",
       "min       1.000000    70.000000    70.000000    80.000000\n",
       "25%       3.000000    84.000000    82.750000    85.000000\n",
       "50%       5.500000   100.000000    95.000000    90.000000\n",
       "75%       8.000000   115.000000   108.000000    95.000000\n",
       "max      10.000000   130.000000   120.000000   100.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('augmented_dataset.csv')\n",
    "df.head()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5965 entries, 0 to 5998\n",
      "Data columns (total 16 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   PatientID    5965 non-null   object\n",
      " 1   Question No  5965 non-null   int64 \n",
      " 2   Emotion1     5965 non-null   object\n",
      " 3   Emotion2     5965 non-null   object\n",
      " 4   Emotion3     5965 non-null   object\n",
      " 5   Emotion4     5965 non-null   object\n",
      " 6   Emotion5     5965 non-null   object\n",
      " 7   Emotion6     5965 non-null   object\n",
      " 8   Emotion7     5965 non-null   object\n",
      " 9   Emotion8     5965 non-null   object\n",
      " 10  Emotion9     5965 non-null   object\n",
      " 11  Emotion10    5965 non-null   object\n",
      " 12  Sentiment    5965 non-null   object\n",
      " 13  GADscore     5965 non-null   int64 \n",
      " 14  HeartRate    5965 non-null   int64 \n",
      " 15  OxygenLevel  5965 non-null   int64 \n",
      "dtypes: int64(4), object(12)\n",
      "memory usage: 792.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('augmented_dataset.csv')\n",
    "\n",
    "# Define weights for each feature\n",
    "weights = {\n",
    "    'Emotion1': {'fear': 2, 'angry': 1, 'neutral': 0, 'happy': 0, 'sad': 0, 'surprise' : 1},\n",
    "    'Emotion2': {'fear': 2, 'angry': 1, 'neutral': 0, 'happy': 0, 'sad': 0, 'surprise' : 1},\n",
    "    'Emotion3': {'fear': 2, 'angry': 1, 'neutral': 0, 'happy': 0, 'sad': 0, 'surprise' : 1},\n",
    "    'Emotion4': {'fear': 2, 'angry': 1, 'neutral': 0, 'happy': 0, 'sad': 0, 'surprise' : 1},\n",
    "    'Emotion5': {'fear': 2, 'angry': 1, 'neutral': 0, 'happy': 0, 'sad': 0, 'surprise' : 1},\n",
    "    'Emotion6': {'fear': 2, 'angry': 1, 'neutral': 0, 'happy': 0, 'sad': 0, 'surprise' : 1},\n",
    "    'Emotion7': {'fear': 2, 'angry': 1, 'neutral': 0, 'happy': 0, 'sad': 0, 'surprise' : 1},\n",
    "    'Emotion8': {'fear': 2, 'angry': 1, 'neutral': 0, 'happy': 0, 'sad': 0, 'surprise' : 1},\n",
    "    'Emotion9': {'fear': 2, 'angry': 1, 'neutral': 0, 'happy': 0, 'sad': 0, 'surprise' : 1},\n",
    "    'Emotion10': {'fear': 2, 'angry': 1, 'neutral': 0, 'happy': 0, 'sad': 0, 'surprise' : 1},\n",
    "    'Sentiment': {'positive': 1, 'negative': 1, 'neutral': 0},\n",
    "    'GADscore': {'low': 0, 'high': 2},  \n",
    "    'HeartRate': {'low': 0, 'high': 2}, \n",
    "    'OxygenLevel': {'low': 0, 'high': 2}\n",
    "}\n",
    "\n",
    "# Define a function to determine if a person has anxiety based on emotions and other features\n",
    "def has_anxiety(row):\n",
    "    total_weight = sum(weights[col].get(row[col], 0) for col in weights.keys())\n",
    "    return total_weight > 0  # Considered anxious if total weight is greater than 0\n",
    "\n",
    "\n",
    "# Apply the function to each row to determine anxiety status\n",
    "df['Anxiety'] = df.apply(has_anxiety, axis=1)\n",
    "\n",
    "# Convert boolean values to 'Yes' and 'No'\n",
    "df['Anxiety'] = df['Anxiety'].map({True: 'Yes', False: 'No'})\n",
    "\n",
    "# Save the dataset with the anxiety column to a new CSV file\n",
    "df.to_csv('dataset_with_anxiety.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question No</th>\n",
       "      <th>GADscore</th>\n",
       "      <th>HeartRate</th>\n",
       "      <th>OxygenLevel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.500000</td>\n",
       "      <td>100.007500</td>\n",
       "      <td>95.043167</td>\n",
       "      <td>89.949000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.872521</td>\n",
       "      <td>17.696515</td>\n",
       "      <td>14.677586</td>\n",
       "      <td>6.014241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>82.750000</td>\n",
       "      <td>85.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.500000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Question No     GADscore    HeartRate  OxygenLevel\n",
       "count  6000.000000  6000.000000  6000.000000  6000.000000\n",
       "mean      5.500000   100.007500    95.043167    89.949000\n",
       "std       2.872521    17.696515    14.677586     6.014241\n",
       "min       1.000000    70.000000    70.000000    80.000000\n",
       "25%       3.000000    84.000000    82.750000    85.000000\n",
       "50%       5.500000   100.000000    95.000000    90.000000\n",
       "75%       8.000000   115.000000   108.000000    95.000000\n",
       "max      10.000000   130.000000   120.000000   100.000000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset_with_anxiety.csv')\n",
    "df.head()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5965 entries, 0 to 5998\n",
      "Data columns (total 17 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   PatientID    5965 non-null   object\n",
      " 1   Question No  5965 non-null   int64 \n",
      " 2   Emotion1     5965 non-null   object\n",
      " 3   Emotion2     5965 non-null   object\n",
      " 4   Emotion3     5965 non-null   object\n",
      " 5   Emotion4     5965 non-null   object\n",
      " 6   Emotion5     5965 non-null   object\n",
      " 7   Emotion6     5965 non-null   object\n",
      " 8   Emotion7     5965 non-null   object\n",
      " 9   Emotion8     5965 non-null   object\n",
      " 10  Emotion9     5965 non-null   object\n",
      " 11  Emotion10    5965 non-null   object\n",
      " 12  Sentiment    5965 non-null   object\n",
      " 13  GADscore     5965 non-null   int64 \n",
      " 14  HeartRate    5965 non-null   int64 \n",
      " 15  OxygenLevel  5965 non-null   int64 \n",
      " 16  Anxiety      5965 non-null   object\n",
      "dtypes: int64(4), object(13)\n",
      "memory usage: 838.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.info()\n",
    "\n",
    "# Convert to csv\n",
    "\n",
    "df.to_csv('final_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('final_dataset.csv')\n",
    "\n",
    "# Define the columns to check for neutral values\n",
    "columns_to_check = ['Emotion1', 'Emotion2', 'Emotion3', 'Emotion4', 'Emotion5', 'Emotion6', 'Emotion7', 'Emotion8', 'Emotion9', 'Emotion10', 'Sentiment']\n",
    "\n",
    "# Find rows where all specified columns have the value 'neutral'\n",
    "neutral_rows = df[(df[columns_to_check] == 'neutral').all(axis=1)]\n",
    "\n",
    "# Remove the neutral rows from the DataFrame\n",
    "df_cleaned = df.drop(neutral_rows.index)\n",
    "\n",
    "# Save the cleaned DataFrame if needed\n",
    "df_cleaned.to_csv('cleaned_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Emotion10\n",
       "neutral     2173\n",
       "sad          685\n",
       "fear         364\n",
       "angry        340\n",
       "happy        331\n",
       "surprise      74\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('cleaned_dataset.csv')\n",
    "#tell how much time the emotion is repeated in this csv\n",
    "df['Emotion1'].value_counts()\n",
    "df['Emotion2'].value_counts()\n",
    "df['Emotion3'].value_counts()\n",
    "df['Emotion4'].value_counts()\n",
    "df['Emotion5'].value_counts()\n",
    "df['Emotion6'].value_counts()\n",
    "df['Emotion7'].value_counts()\n",
    "df['Emotion8'].value_counts()\n",
    "df['Emotion9'].value_counts()\n",
    "df['Emotion10'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Anxiety\n",
       "Yes    2627\n",
       "No     1340\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('cleaned_dataset.csv')\n",
    "df.head()\n",
    "\n",
    "#check frequecy of yes or no\n",
    "df['Anxiety'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('cleaned_dataset.csv')\n",
    "\n",
    "# Drop non-numeric columns and target column\n",
    "X = df.drop(columns=['PatientID', 'Question No', 'Anxiety'])\n",
    "y = df['Anxiety']\n",
    "\n",
    "# Perform one-hot encoding on categorical columns\n",
    "encoder = OneHotEncoder(drop='first')\n",
    "X_encoded = encoder.fit_transform(X.select_dtypes(include=['object']))\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8438287153652393\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize the Multinomial Naive Bayes model\n",
    "model = MultinomialNB()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8438287153652393\n",
      "Confusion Matrix:\n",
      "[[197  71]\n",
      " [ 53 473]]\n",
      "F1 Score: 0.8841121495327102\n",
      "Precision: 0.8694852941176471\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.79      0.74      0.76       268\n",
      "         Yes       0.87      0.90      0.88       526\n",
      "\n",
      "    accuracy                           0.84       794\n",
      "   macro avg       0.83      0.82      0.82       794\n",
      "weighted avg       0.84      0.84      0.84       794\n",
      "\n",
      "Validation Accuracy: 0.9685138539042821\n"
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Initialize the Multinomial Naive Bayes model\n",
    "model = MultinomialNB()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Calculate the F1 score\n",
    "f1 = f1_score(y_test, y_pred, pos_label='Yes')\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Calculate the precision\n",
    "precision = precision_score(y_test, y_pred, pos_label='Yes')\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Generate classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Assuming df contains your dataset\n",
    "X = df.drop(columns=['PatientID', 'Question No', 'Anxiety'])  # Features\n",
    "y = df['Anxiety']  # Target variable\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the column transformer for one-hot encoding\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('cat', OneHotEncoder(), categorical_cols)],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_encoded = preprocessor.fit_transform(X_train)\n",
    "X_test_encoded = preprocessor.transform(X_test)\n",
    "\n",
    "# Initialize the Multinomial Naive Bayes model\n",
    "model = MultinomialNB()\n",
    "\n",
    "# Train the model on the training set\n",
    "model.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = model.predict(X_test_encoded)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Validation Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9676334594367382\n",
      "Validation Accuracy: 0.9760705289672544\n",
      "Testing Accuracy: 0.9659949622166247\n",
      "Confusion Matrix:\n",
      "[[268   0]\n",
      " [ 27 499]]\n",
      "F1 Score: 0.9736585365853657\n",
      "Precision: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.91      1.00      0.95       268\n",
      "         Yes       1.00      0.95      0.97       526\n",
      "\n",
      "    accuracy                           0.97       794\n",
      "   macro avg       0.95      0.97      0.96       794\n",
      "weighted avg       0.97      0.97      0.97       794\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Testing the model\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('cleaned_dataset.csv')\n",
    "\n",
    "# Assuming df contains your dataset\n",
    "X = df.drop(columns=['PatientID', 'Question No', 'Anxiety'])  # Features\n",
    "y = df['Anxiety']  # Target variable\n",
    "\n",
    "# Split the dataset into training, validation, and testing sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "# Define the column transformer for one-hot encoding\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('cat', OneHotEncoder(), categorical_cols)],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_encoded = preprocessor.fit_transform(X_train)\n",
    "X_val_encoded = preprocessor.transform(X_val)\n",
    "X_test_encoded = preprocessor.transform(X_test)\n",
    "\n",
    "# Initialize the Multinomial Naive Bayes model\n",
    "model = MultinomialNB()\n",
    "\n",
    "# Train the model on the training set\n",
    "model.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_pred_train = model.predict(X_train_encoded)\n",
    "\n",
    "# Calculate the training accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred_val = model.predict(X_val_encoded)\n",
    "\n",
    "# Calculate the validation accuracy\n",
    "val_accuracy = accuracy_score(y_val, y_pred_val)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred_test = model.predict(X_test_encoded)\n",
    "\n",
    "# Calculate the testing accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Accuracy:\", test_accuracy)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_test)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Calculate the F1 score\n",
    "f1 = f1_score(y_test, y_pred_test, pos_label='Yes')\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Calculate the precision\n",
    "precision = precision_score(y_test, y_pred_test, pos_label='Yes')\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Generate classification report\n",
    "class_report = classification_report(y_test, y_pred_test)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: No\n"
     ]
    }
   ],
   "source": [
    "# Collect input data from the user\n",
    "input_data = {\n",
    "    'Emotion1': 'sad',\n",
    "    'Emotion2': 'happy',\n",
    "    'Emotion3': 'happy',\n",
    "    'Emotion4': 'sad',\n",
    "    'Emotion5': 'happy',\n",
    "    'Emotion6': 'happy',\n",
    "    'Emotion7': 'happy',\n",
    "    'Emotion8': 'happy',\n",
    "    'Emotion9': 'neutral',\n",
    "    'Emotion10': 'happy',\n",
    "    'Sentiment': 'neutral',\n",
    "    'GADscore': 104,\n",
    "    'HeartRate': 76,\n",
    "    'OxygenLevel': 84\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the input data\n",
    "input_df = pd.DataFrame([input_data])\n",
    "\n",
    "# Preprocess the input data\n",
    "input_encoded = preprocessor.transform(input_df)\n",
    "\n",
    "# Make predictions using the trained model\n",
    "prediction = model.predict(input_encoded)\n",
    "\n",
    "# Display the prediction\n",
    "print(\"Prediction:\", prediction[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
